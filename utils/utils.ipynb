{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO/yh+4ZUx5s3uh66G+OVsB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"J5gWuQV2g5Q5"},"source":["def install_requirements():\n","  !pip install segmentation-models-pytorch\n","  !pip install wandb\n","\n","def connect_to_drive():\n","  from google.colab import drive\n","  drive.mount('/content/gdrive', force_remount=True)\n","\n","def split_dataset_into_train_and_valid(dataset, percentage_train):\n","  lengths = [int(len(dataset)*percentage_train), len(dataset)-int(len(dataset)*percentage_train)]\n","  train_dataset, valid_dataset = random_split(dataset, lengths)\n","  return train_dataset, valid_dataset\n","\n","def save_paths_images(list_paths, title):\n","  f  = open(title, \"w\")\n","  for path in list_paths:\n","    f.write(\"%s\" % str(path)+'\\n')\n","  f.close()\n","\n","def create_list_images_paths_from_folder(input_path_training, input_path_test):\n","  imgs_training = [path for path in sorted(Path(input_path_training).glob(\"**/*.png\")) if 'seg' not in str(path).split('/')[-1]]\n","  random.shuffle(imgs_training)\n","  training_imgs_list = imgs_training[:160]\n","  validation_imgs_list = imgs_training[160:]\n","  test_imgs_list = [path for path in sorted(Path(input_path_test).glob(\"**/*.png\")) if 'seg' not in str(path).split('/')[-1]]\n","  return training_imgs_list, validation_imgs_list, test_imgs_list\n","\n","def read_list_images_path_from_txt(txt_path):\n","  with open(txt_path) as f:\n","    content = f.readlines()\n","    content = [x.strip() for x in content]\n","    return content\n","  f.close()\n","\n","import matplotlib.pyplot as plt\n","\n","def visualize_image_label_overlay(img, label, alpha):\n","  '''\n","  img is a tensor, label is a numpy array\n","  '''\n","  plt.imshow(img.permute(1,2,0))\n","  plt.imshow(label.transpose(1,2,0).squeeze(), cmap='Greys', alpha=alpha)\n","  plt.show()\n","\n","\n","colour_dictionary={\n","    'white':torch.Tensor([255,255,255]),\n","    'green':torch.Tensor([118,246,165]),\n","    'red': torch.Tensor([245,119,65]),\n","    'blue': torch.Tensor([107,136,250])\n","}\n","\n","def visualize_prediction(prediction, label, colour_dictionary):\n","  '''\n","  prediction and label are two numpy arrays in two dimensions WxH\n","  White=TN, Green=TP, RED=FP, BLUE=FN\n","  '''\n","  visualization=np.empty(shape=(prediction.shape[0],prediction.shape[1],3))\n","  for i in range(prediction.shape[0]):\n","    for j in range(prediction.shape[1]):\n","      if prediction[i][j]==1 and label[i][j]==1: #TP\n","        visualization[i,j,:]=colour_dictionary['green']\n","      if prediction[i][j]==0 and label[i][j]==0: #TN\n","        visualization[i,j,:]=colour_dictionary['white']\n","      if prediction[i][j]==0 and label[i][j]==1: #FN\n","        visualization[i,j,:]=colour_dictionary['blue']\n","      if prediction[i][j]==1 and label[i][j]==0: #FP\n","        visualization[i,j,:]=colour_dictionary['red']\n","  plt.imshow(visualization.astype(np.uint8))\n"],"execution_count":null,"outputs":[]}]}
