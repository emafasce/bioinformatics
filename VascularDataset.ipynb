{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VascularDataset.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMv0JBtaxTDibn+i6r5fwqD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"dv_neXaDgOjf"},"source":["import numpy as np\n","from torch.utils.data import Dataset\n","from pathlib import Path\n","import cv2\n","from PIL import Image\n","from torchvision.transforms import *\n","\n","class VascularDataset(Dataset):\n","    \"\"\"\n","    Dataset class for the vascular dataset:\n","    \"\"\"\n","    def __init__(self, list_images_input, list_images_target, mean_normalization=None, std_normalization=None, size=224, crop=None,\n","                 transform=None, return_names=False, return_classification_labels=False):\n","        super(VascularDataset, self).__init__()\n","        self.images_input = list_images_input\n","        self.images_target=list_images_target\n","        self.mean_normalization=mean_normalization\n","        self.std_normalization=std_normalization\n","        self.totensor=ToTensor()\n","        self.normalize=Normalize(self.mean_normalization, self.std_normalization)\n","        self.crop=crop\n","        self.resize=Compose([Resize(size)])\n","        self.transform=transform\n","        self.return_names=return_names\n","        \n","    def __len__(self):\n","        return len(self.images_input)\n","\n","    def __getitem__(self, index):\n","\n","      img_path = str(self.images_input[index])\n","      img = Image.open(img_path).convert('RGB')\n","\n","      seg_path = self.images_target[index]\n","      seg=Image.open(seg_path)\n","      seg = seg.convert('RGB')    # remove the transparent portion of the image\n","      seg = seg.convert('L')      # from RGB to black and white\n","      \n","      #Resize\n","      if self.crop:\n","        cropped = self.crop(image=np.array(img), mask=np.array(seg))          \n","        img = cropped['image']\n","        seg = cropped['mask']\n","\n","      #Transformations\n","      if type(img)==np.ndarray:\n","        img=Image.fromarray(img)\n","        seg=Image.fromarray(seg)\n","        \n","      img=self.resize(img)\n","      seg=self.resize(seg)\n","      \n","      if self.transform:\n","          transformed = self.transform(image=np.array(img), mask=np.array(seg))          \n","          img = transformed['image']\n","          seg = transformed['mask']\n","\n","      seg=(np.array(seg)>0).astype(float)\n","      #seg = seg.point(lambda x: 0 if x < 1 else 255.0, '1')\n","      #seg = np.array(seg, dtype=np.float32)  # equivalent to a cv2 image\n","      seg = np.expand_dims(seg, axis=0)\n","      img=self.totensor(img)\n","\n","      if self.mean_normalization:\n","        img=self.normalize(img)\n","\n","      if self.return_names==True:\n","        return img, img_path, seg, seg_path\n","        \n","      else:\n","        return img, seg\n"],"execution_count":null,"outputs":[]}]}